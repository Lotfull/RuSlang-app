{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import sys\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from shutil import copyfile\n",
    "from ast import literal_eval\n",
    "\n",
    "# Константы\n",
    "all_words_links_path = 'all_words_links.npy'\n",
    "vsekidki_fullwords_csv = 'vsekidki_fullwords.csv'\n",
    "vsekidki_appwords_csv = \"vsekidki_appwords.csv\"\n",
    "vsekidki_words_page = 'vsekidki_words_npy/vsekidki_words_page'\n",
    "length = 45\n",
    "global length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделать all_words_links = [ссылки на все слова] (загрузить с диска)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(all_words_links_path):\n",
    "    all_words_links = np.load(all_words_links_path).tolist()\n",
    "else:\n",
    "    vsekidki_url = \"http://vsekidki.ru/word/page/\"\n",
    "    all_words_links = []\n",
    "    for i in range(1, 45):\n",
    "        r = requests.get(vsekidki_url + str(i) + '/')\n",
    "        data = r.text\n",
    "        soup = BeautifulSoup(data, \"lxml\")\n",
    "        table_of_words = soup.find_all('a', class_='catalogue-heading-link')\n",
    "        for link in table_of_words:\n",
    "            all_words_links.append(link['href'])\n",
    "    len(all_words_links)\n",
    "    np.save(all_words_links_path, all_words_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Text_from_vsekidki_word(text):\n",
    "    start = text.find(\"<\")\n",
    "    finish = text.find(\">\")\n",
    "    text = text[:start] + text[finish + 1:]\n",
    "    print(\"****11111****\", text)\n",
    "    check_for_tag = text.find('<', start)\n",
    "    while check_for_tag != -1:\n",
    "            end_of_tag = text.find('>', check_for_tag)\n",
    "            text = text[:check_for_tag] + text[end_of_tag + 1:]\n",
    "            check_for_tag = text.find('<', check_for_tag)\n",
    "    text = text[:int(len(text)/2)]\n",
    "    return text\n",
    "\n",
    "def print_word(word):\n",
    "    printing = word['name'] + \"\\n    ЗНАЧЕНИЕ: \" + word['definition'].strip() + \"\\n    ПРОИСХОЖДЕНИЕ: \" + word['origin'].strip() + \"\\n\\n\" \n",
    "    print(printing)\n",
    "    for i in range(len(word['fulltext'])):\n",
    "        print(i, word['fulltext'][i])\n",
    "        \n",
    "def find_quote(soup):\n",
    "    quote = \"\"\n",
    "    try:\n",
    "        quote = soup.find('div', class_='quote').text\n",
    "        quote = quote.replace(\"\\'\\'\", \"\\\"\").replace(\",,\", \"\\\"\")\n",
    "    except Exception as msg:\n",
    "        quote = ''\n",
    "    return quote\n",
    "\n",
    "def make_origin(quote):\n",
    "    origin = \"\"\n",
    "    try:\n",
    "        origin = article_body.contents[4].text\n",
    "    except:\n",
    "        try:\n",
    "            origin = article_body.contents[4]\n",
    "        except:\n",
    "            origin = ''\n",
    "    return (origin + quote).encode('iso-8859-1').decode('utf-8').strip()\n",
    "\n",
    "def get_fulltext_from_article_body(article_body):\n",
    "    fulltext = []\n",
    "    for item in article_body.contents[2:]:\n",
    "        utf_str = \"\"\n",
    "        try:\n",
    "            utf_str = item.text.strip().encode('iso-8859-1').decode('utf-8')\n",
    "        except:\n",
    "            try:\n",
    "                utf_str = item.strip().encode('iso-8859-1').decode('utf-8')\n",
    "            except:\n",
    "                try:\n",
    "                    utf_str = item.strip()\n",
    "                except:\n",
    "                    utf_str = \"\"\n",
    "        if utf_str != \"\":\n",
    "            fulltext.append(utf_str)\n",
    "    return fulltext\n",
    "\n",
    "def find_name(soup):\n",
    "    name = \"\"\n",
    "    try:\n",
    "        name = soup.find('h1', class_='new-title').text.encode('iso-8859-1').decode('utf-8').strip()\n",
    "    except:\n",
    "        name = soup.find('h1', class_='new-title').text\n",
    "    return name\n",
    "\n",
    "def make_appwords_file(path):\n",
    "    with open(path, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(('name','definition','type','group','examples','origin','hashtags','synonyms'))\n",
    "        \n",
    "nthng = \"_\"        \n",
    "        \n",
    "def add_appwords_to_file(dict, path):\n",
    "    with open(path, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for word in dict:\n",
    "            writer.writerow((word['name'],word['definition'],\"\",\"\",\"\",word['origin'],\"\",nthng))\n",
    "  \n",
    "def make_fullwords_file(path):\n",
    "    with open(path, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(('name','fulltext'))\n",
    "\n",
    "\n",
    "def add_fullwords_to_file(dict, path):\n",
    "    with open(path, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for word in dict:\n",
    "            writer.writerow((word['name'], word['fulltext']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распарсить pages from 1 to length, поместить их в vsekidki_words_page(i).npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      " ГОТОВО\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, length):\n",
    "    # to rewrite all files delete \"not\"\n",
    "    if not os.path.isfile(vsekidki_words_page + str(i) + '.npy'):\n",
    "        words = []\n",
    "        print(\" PAGE \", i)\n",
    "        for word_link in all_words_links[(i)*30: (i + 1)*30 + 1]:\n",
    "            r = requests.get(word_link)\n",
    "            soup = BeautifulSoup(r.text, \"lxml\")\n",
    "            article_body = soup.find('div', itemprop='articleBody')\n",
    "            name = find_name(soup)\n",
    "            definition = article_body.contents[2].encode('iso-8859-1').decode('utf-8').strip()\n",
    "            quote = find_quote(soup)\n",
    "            origin = make_origin(quote=quote)\n",
    "            fulltext = get_fulltext_from_article_body(article_body)\n",
    "            word = {\"name\": name,\n",
    "                    \"origin\": origin,\n",
    "                    \"definition\": definition,\n",
    "                    \"fulltext\": fulltext}\n",
    "            words.append(word)\n",
    "        dict_path = vsekidki_words_page + str(i) + '.npy'\n",
    "        np.save(dict_path, words)\n",
    "print(\"*********\\n ГОТОВО\\n*********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## сделать all_words - массив всех слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слов: 1350\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for i in range(0, length):\n",
    "    read_dictionary = np.load(vsekidki_words_page + str(i) + '.npy').tolist()\n",
    "    all_words += read_dictionary   \n",
    "print(\"Слов:\", len(all_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранить all_words в vsekidki_dict.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_fullwords_file(vsekidki_fullwords_csv)\n",
    "add_fullwords_to_file(all_words, vsekidki_fullwords_csv)\n",
    "\n",
    "make_appwords_file(vsekidki_appwords_csv)\n",
    "add_appwords_to_file(all_words, vsekidki_appwords_csv)\n",
    "\n",
    "fullwords_df = pd.read_csv(vsekidki_fullwords_csv)\n",
    "appwords_df = pd.read_csv(vsekidki_appwords_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>definition</th>\n",
       "      <th>type</th>\n",
       "      <th>group</th>\n",
       "      <th>examples</th>\n",
       "      <th>origin</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АУЕ</td>\n",
       "      <td>А.У.Е расшифровка: Жизнь Ворам Сметь мусорам. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Воряги так говорят, переводится как АРЕСТАНСКИ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Патимейкер</td>\n",
       "      <td>Новая песня с незамысловатым текстом. Автор - ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Патимейкеры это те, кто организовывают тусу (д...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аксемора</td>\n",
       "      <td>Аксиомора ошибочное произнесение слова \"оксюмо...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Компания \"Мегафон\" переозвучила свою рекламу с...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                         definition  type  group  \\\n",
       "0         АУЕ  А.У.Е расшифровка: Жизнь Ворам Сметь мусорам. ...   NaN    NaN   \n",
       "1  Патимейкер  Новая песня с незамысловатым текстом. Автор - ...   NaN    NaN   \n",
       "2    Аксемора  Аксиомора ошибочное произнесение слова \"оксюмо...   NaN    NaN   \n",
       "\n",
       "   examples                                             origin  hashtags  \\\n",
       "0       NaN  Воряги так говорят, переводится как АРЕСТАНСКИ...       NaN   \n",
       "1       NaN  Патимейкеры это те, кто организовывают тусу (д...       NaN   \n",
       "2       NaN  Компания \"Мегафон\" переозвучила свою рекламу с...       NaN   \n",
       "\n",
       "  synonyms  \n",
       "0        _  \n",
       "1        _  \n",
       "2        _  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appwords_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АУЕ</td>\n",
       "      <td>['А.У.Е расшифровка: Жизнь Ворам Сметь мусорам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Патимейкер</td>\n",
       "      <td>['Новая песня с незамысловатым текстом. Автор ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аксемора</td>\n",
       "      <td>['Аксиомора ошибочное произнесение слова \"оксю...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                           fulltext\n",
       "0         АУЕ  ['А.У.Е расшифровка: Жизнь Ворам Сметь мусорам...\n",
       "1  Патимейкер  ['Новая песня с незамысловатым текстом. Автор ...\n",
       "2    Аксемора  ['Аксиомора ошибочное произнесение слова \"оксю..."
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullwords_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
